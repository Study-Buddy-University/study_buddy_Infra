# =============================================================================
# WINDOWS NATIVE OLLAMA CONFIGURATION
# =============================================================================
# This configuration is optimized for Windows systems using native Ollama
# installation instead of Docker Ollama container.
#
# SETUP INSTRUCTIONS:
# 1. Install Ollama for Windows: winget install --id=Ollama.Ollama -e
# 2. Copy this file contents to: infrastructure/.env
# 3. Pull required models:
#    ollama pull qwen2.5:0.5b
#    ollama pull nomic-embed-text
# 4. Start services:
#    docker compose -f docker-compose.windows.yml up -d
#
# See docs/WINDOWS_NATIVE_OLLAMA_SETUP.md for detailed instructions
# =============================================================================

# Database Configuration
POSTGRES_DB=studybuddy
POSTGRES_USER=postgres
POSTGRES_PASSWORD=studybuddy_secure_2024

# Ollama Configuration (Native Windows Ollama)
# Points to Windows host Ollama service (not Docker container)
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:0.5b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Backend Configuration
API_BASE_URL=http://localhost:8001

# Development Settings
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# CPU Mode (for systems without GPU support)
GPU_TYPE=cpu

# =============================================================================
# NOTES:
# - OLLAMA_BASE_URL points to host.docker.internal (Windows Ollama, not Docker)
# - OLLAMA_MODEL is set to qwen2.5:0.5b (fast, CPU-friendly)
# - OLLAMA_EMBEDDING_MODEL uses nomic-embed-text (optimized for embeddings)
# - GPU_TYPE=cpu (no GPU acceleration needed for small models)
#
# AFTER SETUP:
# 1. Restart backend: docker compose -f docker-compose.windows.yml restart backend
# 2. Reset ChromaDB: docker compose -f docker-compose.windows.yml exec backend python scripts/reset_chromadb.py
# 3. Re-upload documents through UI
# =============================================================================
